---
layout: post
title: 'Adventures in Freebernetes: My Out-of-Control Plane'
date: 2020-11-28 08:10:28.000000000 -08:00
type: post
parent_id: '0'
published: true
password: ''
status: publish
categories:
- FreeBSD Virtualization
tags:
- dns
- freebsd
- ipv4
- kubernetes
- linux
- virtualization
meta:
  _thumbnail_id: '1377'
  _wpcom_is_markdown: '1'
  _last_editor_used_jetpack: block-editor
  _oembed_783ce91522136c3d54332a75c68a3c32: <div class="embed-twitter"><blockquote
    class="twitter-tweet" data-width="550" data-dnt="true"><p lang="en" dir="ltr">I
    won&#39;t give out and do not want the root password on a Linux host ever again,
    but I cannot bring myself to install sudo on my personal FreeBSD machines.<br><br>wheel
    group and su -<br><br>That is the way.</p>&mdash; Karen Bruner (@fuzzyKB) <a href="https://twitter.com/fuzzyKB/status/1330424565772791813?ref_src=twsrc%5Etfw">November
    22, 2020</a></blockquote><script async src="https://platform.twitter.com/widgets.js"
    charset="utf-8"></script></div>
  _oembed_time_783ce91522136c3d54332a75c68a3c32: '1606369584'
  timeline_notification: '1606551032'
  _publicize_job_id: '51575486994'
  _oembed_b888abc0a2e55f0924270ac6641252a1: <div class="embed-twitter"><blockquote
    class="twitter-tweet" data-width="500" data-dnt="true"><p lang="en" dir="ltr">I
    won&#39;t give out and do not want the root password on a Linux host ever again,
    but I cannot bring myself to install sudo on my personal FreeBSD machines.<br><br>wheel
    group and su -<br><br>That is the way.</p>&mdash; Karen Bruner (@fuzzyKB) <a href="https://twitter.com/fuzzyKB/status/1330424565772791813?ref_src=twsrc%5Etfw">November
    22, 2020</a></blockquote><script async src="https://platform.twitter.com/widgets.js"
    charset="utf-8"></script></div>
  _oembed_time_b888abc0a2e55f0924270ac6641252a1: '1606677185'
  _oembed_bbe84bd42b38af1494216129d52f11e9: "{{unknown}}"
  _oembed_a33c1bf2aa4ab7a4c4dc738762113b54: "{{unknown}}"
  _oembed_2d39c4d28068be1e7b19c958e9d2e0b9: "{{unknown}}"
author:
  login: nightmarebeforedevops
  email: kbcontactxyz@gmail.com
  display_name: karenb
  first_name: Karen
  last_name: Bruner
permalink: "/2020/11/28/adventures-in-freebernetes-my-out-of-control-plane/"
excerpt: 'Part 11 of experiments in FreeBSD and Kubernetes: Bootstrapping the Kubernetes
  Control Plane'
---
<p><!-- wp:paragraph {"fontSize":"medium"} --></p>
<p class="has-medium-font-size"><em>Part 11 of experiments in FreeBSD and Kubernetes: Bootstrapping</em> <em>the Kubernetes Control Plane</em></p>
<p><!-- /wp:paragraph --></p>
<p><!-- wp:paragraph {"fontSize":"normal"} --></p>
<p class="has-normal-font-size"><a href="https://productionwithscissors.run/freebsd-virtualization-series/"><em>See all posts in this series</em></a></p>
<p><!-- /wp:paragraph --></p>
<p><!-- wp:heading {"level":4} --></p>
<h4>Table of Contents</h4>
<p><!-- /wp:heading --></p>
<p><!-- wp:html --></p>
<div class="toc">
<ol>
<li><a href="#recap">Recap</a></li>
<li><a href="#bootstrapping-etcd-cluster">Bootstrapping the etcd Cluster</a></li>
<li><a href="#bootstrapping-control-plane">Bootstrapping the Kubernetes Control Plane</a></li>
<ul>
<li><a href="#rabbit-hole-3-load-balancing">Rabbit Hole #3: Load Balancing Revisited</a></li>
<li><a href="#verifying-control-plane">Verifying the Control Plane</a></li>
</ul>
<li><a href="#sources-references">Sources / References</a></li>
</ol>
<p>
</div>
<p><!-- /wp:html --></p>
<p><!-- wp:heading --></p>
<h2 id="recap">Recap</h2>
<p><!-- /wp:heading --></p>
<p><!-- wp:paragraph --></p>
<p>In <a href="https://productionwithscissors.run/2020/11/26/adventures-in-freebernetes-certs-certs-dns-more-certs/">the previous post</a> in this series, I created my Kubernetes cluster's <a href="https://productionwithscissors.run/2020/11/26/adventures-in-freebernetes-certs-certs-dns-more-certs/#creating-instances">virtual machines</a>, <a href="https://productionwithscissors.run/2020/11/26/adventures-in-freebernetes-certs-certs-dns-more-certs/#generating-certificate-authority">the cluster certificates</a>, and <a href="https://productionwithscissors.run/2020/11/26/adventures-in-freebernetes-certs-certs-dns-more-certs/#generating-kubernetes-configuration-files">client authentication files</a>, following the tutorial in <a href="https://github.com/kelseyhightower/kubernetes-the-hard-way">Kubernetes the Hard Way</a>. I also set up an authoritative <a href="https://productionwithscissors.run/2020/11/26/adventures-in-freebernetes-certs-certs-dns-more-certs/#rabbit-hole-1-dns">DNS</a> server to handle my local zone on the hypervisor, as well as creating firewall rules to <a href="https://productionwithscissors.run/2020/11/26/adventures-in-freebernetes-certs-certs-dns-more-certs/#rabbit-hole-2-fake-load-balancing">load balance</a> across the three controller instances. Now I'm ready to bootstrap <code>etcd</code>.</p>
<p><!-- /wp:paragraph --></p>
<p><!-- wp:paragraph --></p>
<p>A few details for reference:</p>
<p><!-- /wp:paragraph --></p>
<p><!-- wp:list --></p>
<ul>
<li>My hypervisor is named <code>nucklehead</code> (it's an Intel NUC) and is running FreeBSD 13.0-CURRENT</li>
<li>My home network, including the NUC, is in the 192.168.0.0/16 space</li>
<li>The Kubernetes cluster will exist in the 10.0.0.0/8 block, which exists solely on my FreeBSD host.
<ul>
<li>The controllers and workers are in the 10.10.0.0/24 block.</li>
<li>The control plane service network is in the 10.50.0.0/24 block.</li>
<li>The cluster pod network is in the 10.100.0.0/16 block.</li>
<li>The cluster service network has the 10.110.0.0/24 block.</li>
</ul>
</li>
<li>The cluster VMs are all in the <code>something.local</code> domain.</li>
<li>The <code>kubernetes.something.local</code> endpoint for <code>kube-apiserver</code> has the virtual IP address 10.10.0.1, which gets round-robin load-balanced across all three controllers by <code>ipfw</code> on the hypervisor.</li>
<li>Yes, I am just hanging out in a root shell on the hypervisor.</li>
</ul>
<p><!-- /wp:list --></p>
<p><!-- wp:heading --></p>
<h2 id="bootstrapping-etcd-cluster"><a href="https://github.com/kelseyhightower/kubernetes-the-hard-way/blob/1.18.6/docs/07-bootstrapping-etcd.md">Bootstrapping the etcd Cluster</a></h2>
<p><!-- /wp:heading --></p>
<p><!-- wp:paragraph --></p>
<p>First off, I fire up tmux, create three panes, then google to figure out how to split them more or less evenly. Then I spend another five minutes trying to fix the <code>term</code> type because I've finally lost patience with getting rows of <code>q</code> instead of a solid border. However, nothing I try seems to fix it and I can't find anything on the net, so this is what my window looks like and why am I reading <code>/etc/termcap</code> in the year 2020?</p>
<p><!-- /wp:paragraph --></p>
<p><!-- wp:image {"id":1368,"sizeSlug":"large","linkDestination":"none"} --></p>
<figure class="wp-block-image size-large"><img src="{{ site.baseurl }}/assets/images/2020/11/screenshot-2020-11-27-at-02.27.58-01.jpeg?w=707" alt="Screen shot of my terminal with three tmux panes divided by lines of q" class="wp-image-1368" /></figure>
<p><!-- /wp:image --></p>
<p><!-- wp:image {"id":1370,"sizeSlug":"large","linkDestination":"none"} --></p>
<figure class="wp-block-image size-large"><img src="{{ site.baseurl }}/assets/images/2020/11/screenshot-2020-11-27-at-02.58.19-01.jpeg?w=707" alt="Screenshot of terminal with three tmux panes setting the IP and name variables on each controller VM" class="wp-image-1370" /></figure>
<p><!-- /wp:image --></p>
<p><!-- wp:paragraph --></p>
<p>And done.</p>
<p><!-- /wp:paragraph --></p>
<p><!-- wp:image {"id":1372,"sizeSlug":"large","linkDestination":"none"} --></p>
<figure class="wp-block-image size-large"><img src="{{ site.baseurl }}/assets/images/2020/11/screenshot-2020-11-27-at-03.54.07-01.jpeg?w=707" alt="Screenshot of 3 panes in tmux showing each controller has etcd running" class="wp-image-1372" /></figure>
<p><!-- /wp:image --></p>
<p><!-- wp:heading --></p>
<h2 id="bootstrapping-control-plane"><a href="https://github.com/kelseyhightower/kubernetes-the-hard-way/blob/1.18.6/docs/08-bootstrapping-kubernetes-controllers.md">Bootstrapping the Kubernetes Control Plane</a></h2>
<p><!-- /wp:heading --></p>
<p><!-- wp:paragraph --></p>
<p>I didn't read the section on certificate creation closely enough, so I missed the part about how the Kube API service IP should (must?) be part of a dedicated block for control plane services. My current <code>kube-apiserver</code> endpoint is currently in the same block as the VMs, so I will use 10.50.0.0/24 for the service block. I quickly redo the virtual IPs I added to the controllers and the <code>ipfw</code> rules on the hypervisor, then update the DNS record for <code>kubernetes.something.local</code> to 10.50.0.1.</p>
<p><!-- /wp:paragraph --></p>
<p><!-- wp:heading {"level":3} --></p>
<h3 id="rabbit-hole-3-load-balancing">Rabbit Hole #3: Load Balancing Revisited</h3>
<p><!-- /wp:heading --></p>
<p><!-- wp:paragraph --></p>
<p>After I set up the <code>nginx</code> reverse proxy with its passthrough to <code>kube-apiserver</code>'s <code>/healthz</code> endpoint on each controller, I wondered a bit if I should revisit the cut-rate load balancing I had set up using <code>ipfw</code> and VIPs. While it spreads the requests to the Kubernetes API's virtual service address across the three controllers, it has no <a href="https://github.com/kelseyhightower/kubernetes-the-hard-way/blob/1.18.6/docs/08-bootstrapping-kubernetes-controllers.md#enable-http-health-checks">health check</a> support to make sure it's not sending a request to a server that cannot respond, and <code>ipfw</code> does not support such a thing.</p>
<p><!-- /wp:paragraph --></p>
<p><!-- wp:paragraph --></p>
<p>I consider a few options:</p>
<p><!-- /wp:paragraph --></p>
<p><!-- wp:list --></p>
<ul>
<li>Create a service on the FreeBSD hypervisor that runs the health check for each backend and then updates the <code>ipfw</code> rules as needed; requires maintaining another service and also requires ensuring I don't mangle my firewall in the process.</li>
<li>Instead of using a virtual IP address for the API endpoint, convert it to a round-robin DNS record. Using a custom service health-check like the one mentioned above, the service could update the DNS zone to remove a failed backend host. This option would actually be worse than updating <code>ipfw</code> rules, because not only because I would risk mangling my DNS zone. I would also have to deal with time-to-live (TTL) for the DNS record, which requires balancing a low TTL which carries frequent DNS lookups versus using a longer TTL, which can make the time to fail over unpredictable for clients. Round-robin DNS is clearly not a better option, but I mention it because round-robin records often buy simplicity of implementation at the price of multiple headaches down the road.</li>
<li>Add a reverse proxy service on the hypervisor, such as <code>nginx</code> or <code>haproxy</code>, to query the <code>/healthz</code> endpoint on each backend and avoid sending incoming requests to servers that are unhealthy. Unlike the <code>ipfw</code> round-robin, this solution runs in user space rather than in the kernel, which means it adds a performance hit and also requires managing another service.</li>
<li>Use CARP (Common Address Redundancy Protocol) for failover. While I had originally thought I could use <a href="https://www.freebsd.org/doc/handbook/carp.html">CARP</a> on the FreeBSD host to handle some form of failover, it became clear that was not an option, because CARP has to be configured on the endpoint servers themselves. However, I could use the Linux analog <code>ucarp</code> to create server failover between the controllers.</li>
</ul>
<p><!-- /wp:list --></p>
<p><!-- wp:paragraph --></p>
<p>I ended up not setting up CARP for a few reasons:</p>
<p><!-- /wp:paragraph --></p>
<p><!-- wp:list --></p>
<ul>
<li>Unlike FreeBSD's implementation, which runs as an in-kernel module, Linux's <code>ucarp</code> runs as a service in userland. In other words, it requires managing yet another service on each of the controllers.</li>
<li>Neither CARP implementation can monitor a specific service port for liveness. Failover only occurs when the host currently using the configured virtual IP address stops advertising on the network.</li>
<li><code>ucarp</code> only supports pairs of servers for a given virtual IP address, while I have three controllers. I could do something like create three CARP groups, one for each possible pair, and then use those for the endpoints in the <code>ipfw</code> firewall rules. However, that doesn't really solve the problem of a VM advertising on the network but not serving <code>kube-apiserver</code> requests for other reasons. But I had to look at CARP again anyway.</li>
</ul>
<p><!-- /wp:list --></p>
<p><!-- wp:image {"id":1374,"sizeSlug":"large","linkDestination":"none"} --></p>
<figure class="wp-block-image size-large"><img src="{{ site.baseurl }}/assets/images/2020/11/sketch1606526054394-01.jpeg?w=1024" alt="Diagram of 3-way failover with CARP when each controllers sharing a different virtual IP address with each of the other two controllers" class="wp-image-1374" /><br />
<figcaption><em>Diagram showing what a 3-way failover could look like with CARP when you can only have two servers in a group</em></figcaption>
</figure>
<p><!-- /wp:image --></p>
<p><!-- wp:paragraph --></p>
<p>In the end, I decide not to implement a truly highly-available configuration because I'm not creating a production system, I already have more than one single point of failure (SPOF) so what's one more, and I was hoping for a more elegant or a more interesting solution. I'd probably go with setting up a reverse proxy to use as a health-checking load balancer on the FreeBSD hypervisor if I really needed high availability in this scenario.</p>
<p><!-- /wp:paragraph --></p>
<p><!-- wp:heading {"level":3} --></p>
<h3 id="verifying-control-plane"><a href="https://github.com/kelseyhightower/kubernetes-the-hard-way/blob/1.18.6/docs/08-bootstrapping-kubernetes-controllers.md#verification">Verifying the Control Plane</a></h3>
<p><!-- /wp:heading --></p>
<p><!-- wp:paragraph --></p>
<p>After escaping from that rabbit hole, it's time to see if I set up the control plane correctly.</p>
<p><!-- /wp:paragraph --></p>
<p><!-- wp:image {"id":1377,"sizeSlug":"large","linkDestination":"none"} --></p>
<figure class="wp-block-image size-large"><img src="{{ site.baseurl }}/assets/images/2020/11/screenshot-2020-11-27-at-15.10.16-01.jpeg?w=707" alt="Screen shot of shell with three tmux panes showing all three controllers are using an invalid certificate due to missing IP address" class="wp-image-1377" /></figure>
<p><!-- /wp:image --></p>
<p><!-- wp:paragraph --></p>
<p>Well, that's a no. It looks like I somehow missed adding the localhost endpoint when generating one of the certificates (probably the API server's). And come to think of it, I also forgot to update the certificates when I changed the <code>kubernetes.something.local</code> IP address.</p>
<p><!-- /wp:paragraph --></p>
<p><!-- wp:paragraph --></p>
<p>I regenerate <code>kubernetes.pem</code> and then copy it around. Both <code>kube-apiserver</code> and <code>etcd</code> use it, the latter for authenticating peer connections from the API server. I restart the services and... still get the error. I double check the generated cert with <code>openssl x509 -in kubernetes.pem -text</code> and yes, the hostnames are all there in the list of Subject Alternative Names (SANs).</p>
<p><!-- /wp:paragraph --></p>
<p><!-- wp:embed {"url":"https:\/\/gist.github.com\/kbruner\/d50ce38edba57c5ab7bbf04d318acdac","type":"rich","providerNameSlug":"embed","className":""} --></p>
<figure class="wp-block-embed is-type-rich is-provider-embed wp-block-embed-embed">
<div class="wp-block-embed__wrapper">
https://gist.github.com/kbruner/d50ce38edba57c5ab7bbf04d318acdac
</div>
</figure>
<p><!-- /wp:embed --></p>
<p><!-- wp:paragraph --></p>
<p>Except it's odd that the <code>kubectl</code> error tells me the only valid IP addresses are <code>10.10.0.1[0-2]</code> (depending on the controller) and <code>10.0.0.1</code>, the default gateway configured on the VMs. Sooo... I go digging. It looks like <code>kube-apiserver</code>'s default path for certificates is <code>/var/run/kubernetes</code>, which I had created per the tutorial. Sure enough, there were two files there which I had not created: <code>apiserver.crt</code> and <code>apiserver.key</code>. And when I ran the <code>openssl x509 ...</code> command on <code>apiserver.crt</code>, it only had two configured Subject Alternative Names: <code>10.10.0.1[0-2]</code> (depending on the controller) and <code>10.0.0.1</code>.</p>
<p><!-- /wp:paragraph --></p>
<p><!-- wp:paragraph --></p>
<p>I delete those files, restart <code>kube-apiserver</code> and as I expected, it regenerates them, but they still have the same useless SANs. So, I stop everything again, and copy over the damn <code>kubernetes.pem</code> and <code>kubernetes-key.pem</code> (the ones I had created) from <code>/var/lib/kubernetes</code> to <code>/var/run/kubernetes</code> with the appropriate file names, fire everything up (again), and yay, shit works now, let's move on.</p>
<p><!-- /wp:paragraph --></p>
<p><!-- wp:image {"id":1380,"sizeSlug":"large","linkDestination":"none"} --></p>
<figure class="wp-block-image size-large"><img src="{{ site.baseurl }}/assets/images/2020/11/screenshot-2020-11-27-at-23.40.40-01.jpeg?w=707" alt="Screen shot of shell with tmux panes showing the kubectl command now works on all the controllers." class="wp-image-1380" /></figure>
<p><!-- /wp:image --></p>
<p><!-- wp:paragraph --></p>
<p>I configure <code>kubelet</code> RBAC, skip the section on creating a load balancer in Google Cloud since I have my <code>ipfw</code> rules in place and, you know, not in GCP. I test my fake load balancer endpoint, and everything works.</p>
<p><!-- /wp:paragraph --></p>
<p><!-- wp:embed {"url":"https:\/\/gist.github.com\/kbruner\/882b321f8fb66cfc5f40eff621046aed","type":"rich","providerNameSlug":"embed","className":""} --></p>
<figure class="wp-block-embed is-type-rich is-provider-embed wp-block-embed-embed">
<div class="wp-block-embed__wrapper">
https://gist.github.com/kbruner/882b321f8fb66cfc5f40eff621046aed
</div>
</figure>
<p><!-- /wp:embed --></p>
<p><!-- wp:separator --></p>
<hr class="wp-block-separator" />
<!-- /wp:separator --></p>
<p><!-- wp:paragraph --></p>
<p>In the <a href="https://productionwithscissors.run/2020/12/01/adventures-in-freebernetes-tripping-to-the-finish-line/">next installment</a>, I'll start off by bootstrapping the worker nodes and maybe finish building the cluster, depending, as always, on the number of rabbit holes I can't resist.</p>
<p><!-- /wp:paragraph --></p>
<p><!-- wp:heading --></p>
<h2 id="sources-references">Sources / References</h2>
<p><!-- /wp:heading --></p>
<p><!-- wp:list --></p>
<ul>
<li><a rel="noreferrer noopener" href="https://github.com/kelseyhightower/kubernetes-the-hard-way" target="_blank">https://github.com/kelseyhightower/kubernetes-the-hard-way</a></li>
<li><a href="https://kubernetes.io/docs/reference/command-line-tools-reference/kube-apiserver/">https://kubernetes.io/docs/reference/command-line-tools-reference/kube-apiserver/</a></li>
<li><a href="https://manpages.ubuntu.com/manpages/focal/man8/ucarp.8.html">https://manpages.ubuntu.com/manpages/focal/man8/ucarp.8.html</a></li>
<li><a href="https://www.freebsd.org/doc/handbook/firewalls-ipfw.html">https://www.freebsd.org/doc/handbook/firewalls-ipfw.html</a></li>
</ul>
<p><!-- /wp:list --></p>
